{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os, sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    data = []\n",
    "    f = open(file_name,'r')\n",
    "    for line in f:\n",
    "        if '&apos;' in line: continue\n",
    "        data.append(line.strip())\n",
    "    return data\n",
    "data_news = read_data('news_data.txt')\n",
    "data_fed = read_data('fed_data.txt') \n",
    "labels = []\n",
    "for i in range(len(data_news)):\n",
    "    labels.append('geopolitical')\n",
    "for i in range(len(data_fed)):\n",
    "    labels.append('market')\n",
    "\n",
    "df = pd.DataFrame(list(zip(data_news + data_fed, labels)), \n",
    "               columns =['title', 'classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daybreak</td>\n",
       "      <td>geopolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>australia</td>\n",
       "      <td>geopolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>full</td>\n",
       "      <td>geopolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>show</td>\n",
       "      <td>geopolitical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daybreak</td>\n",
       "      <td>geopolitical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title       classes\n",
       "0   daybreak  geopolitical\n",
       "1  australia  geopolitical\n",
       "2       full  geopolitical\n",
       "3       show  geopolitical\n",
       "4   daybreak  geopolitical"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df.classes)\n",
    "X = df.title\n",
    "\n",
    "# Split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25,random_state = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.996422893481717\n",
      "f1 score: 0.9973926204321707\n"
     ]
    }
   ],
   "source": [
    "## Baseline model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# LabelPowerset allows for multi-label classification\n",
    "# Build a pipeline for multinomial naive bayes classification\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1,1))),\n",
    "                     #('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', LabelPowerset(MultinomialNB()))])\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "print('mean accuracy: {}'.format(np.mean(predicted == y_test)))\n",
    "print('f1 score: {}'.format(f1_score(y_test, predicted, average='weighted')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.9844992050874404\n",
      "f1 score: 0.9910872461217234\n"
     ]
    }
   ],
   "source": [
    "## with tfidf transformer:\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1,1))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', LabelPowerset(MultinomialNB(alpha=1e-2))),])\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "print('mean accuracy: {}'.format(np.mean(predicted == y_test)))\n",
    "print('f1 score: {}'.format(f1_score(y_test, predicted, average='weighted')  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try more models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.9952305246422893\n",
      "f1 score: 0.9963897981451173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyuqiu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Test if SVM performs better\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1,1))),\n",
    "                         ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                         ('clf-svm', LabelPowerset(\n",
    "                             SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, max_iter=10, random_state=42)))])\n",
    "_ = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "print('mean accuracy: {}'.format(np.mean(predicted_svm == y_test)))\n",
    "print('f1 score: {}'.format(f1_score(y_test, predicted_svm, average='weighted')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.996422893481717\n",
      "f1 score: 0.9973926204321707\n"
     ]
    }
   ],
   "source": [
    "## random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_clf_rf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1,1))),\n",
    "                         ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                         ('clf-rf', LabelPowerset(\n",
    "                             RandomForestClassifier(n_estimators = 100)))])\n",
    "_ = text_clf_rf.fit(X_train, y_train)\n",
    "predicted_rf = text_clf_rf.predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "print('mean accuracy: {}'.format(np.mean(predicted_rf == y_test)))\n",
    "print('f1 score: {}'.format(f1_score(y_test, predicted_rf, average='weighted')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.9988076311605724\n",
      "f1 score: 0.9991820966353138\n"
     ]
    }
   ],
   "source": [
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "text_clf_gbdt = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1,1))),\n",
    "                         ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                         ('clf-gbdt', LabelPowerset(\n",
    "                             GradientBoostingClassifier(n_estimators=200)))])\n",
    "_ = text_clf_gbdt.fit(X_train, y_train)\n",
    "\n",
    "predicted_gbdt = text_clf_gbdt.predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "print('mean accuracy: {}'.format(np.mean(predicted_gbdt == y_test)))\n",
    "print('f1 score: {}'.format(f1_score(y_test, predicted_gbdt, average='weighted')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.996422893481717\n",
      "f1 score: 0.9973926204321707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyuqiu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "text_clf_lr = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1,1))),\n",
    "                         ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                         ('clf-lr', LabelPowerset(\n",
    "                             LogisticRegression(C=10)))])\n",
    "_ = text_clf_lr.fit(X_train, y_train)\n",
    "predicted_lr = text_clf_lr.predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "np.mean(predicted_lr == y_test)\n",
    "\n",
    "print('mean accuracy: {}'.format(np.mean(predicted_lr == y_test)))\n",
    "print('f1 score: {}'.format(f1_score(y_test, predicted_lr, average='weighted')  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
